{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27a00e97",
   "metadata": {},
   "source": [
    "Import required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "478e9264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Downloading imutils-0.5.4.tar.gz (17 kB)\n",
      "Building wheels for collected packages: imutils\n",
      "  Building wheel for imutils (setup.py): started\n",
      "  Building wheel for imutils (setup.py): finished with status 'done'\n",
      "  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25860 sha256=5cf0e3aca91684285114b3c01714b30a38db6c4578e76c7211380730db2c8fba\n",
      "  Stored in directory: c:\\users\\jagad\\appdata\\local\\pip\\cache\\wheels\\59\\1b\\52\\0dea905f8278d5514dc4d0be5e251967f8681670cadd3dca89\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be180202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: conda-script.py [-h] [-V] command ...\n",
      "\n",
      "conda is a tool for managing and deploying applications, environments and packages.\n",
      "\n",
      "Options:\n",
      "\n",
      "positional arguments:\n",
      "  command\n",
      "    clean        Remove unused packages and caches.\n",
      "    compare      Compare packages between conda environments.\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.    config       Modify configuration values in .condarc. This is modeled\n",
      "\n",
      "                 after the git config command. Writes to the user .condarc\n",
      "                 file (C:\\Users\\jagad\\.condarc) by default.\n",
      "    create       Create a new conda environment from a list of specified\n",
      "                 packages.\n",
      "    help         Displays a list of available conda commands and their help\n",
      "                 strings.\n",
      "    info         Display information about current conda install.\n",
      "    init         Initialize conda for shell interaction. [Experimental]\n",
      "    install      Installs a list of packages into a specified conda\n",
      "                 environment.\n",
      "    list         List linked packages in a conda environment.\n",
      "    package      Low-level conda package utility. (EXPERIMENTAL)\n",
      "    remove       Remove a list of packages from a specified conda environment.\n",
      "    uninstall    Alias for conda remove.\n",
      "    run          Run an executable in a conda environment. [Experimental]\n",
      "    search       Search for packages and display associated information. The\n",
      "                 input is a MatchSpec, a query language for conda packages.\n",
      "                 See examples below.\n",
      "    update       Updates conda packages to the latest compatible version.\n",
      "    upgrade      Alias for conda update.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help     Show this help message and exit.\n",
      "  -V, --version  Show the conda version number and exit.\n",
      "\n",
      "conda commands available from other packages:\n",
      "  build\n",
      "  content-trust\n",
      "  convert\n",
      "  debug\n",
      "  develop\n",
      "  env\n",
      "  index\n",
      "  inspect\n",
      "  metapackage\n",
      "  render\n",
      "  repo\n",
      "  server\n",
      "  skeleton\n",
      "  token\n",
      "  verify\n"
     ]
    }
   ],
   "source": [
    "conda-h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "272f3219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\PIL\\Image.py:962: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training head...\n",
      "Epoch 1/15\n",
      "95/95 [==============================] - 142s 1s/step - loss: 0.4186 - accuracy: 0.8411 - val_loss: 0.1474 - val_accuracy: 0.9817\n",
      "Epoch 2/15\n",
      "95/95 [==============================] - 121s 1s/step - loss: 0.1366 - accuracy: 0.9697 - val_loss: 0.0751 - val_accuracy: 0.9909\n",
      "Epoch 3/15\n",
      "95/95 [==============================] - 129s 1s/step - loss: 0.0976 - accuracy: 0.9720 - val_loss: 0.0535 - val_accuracy: 0.9896\n",
      "Epoch 4/15\n",
      "95/95 [==============================] - 126s 1s/step - loss: 0.0788 - accuracy: 0.9776 - val_loss: 0.0453 - val_accuracy: 0.9922\n",
      "Epoch 5/15\n",
      "95/95 [==============================] - 121s 1s/step - loss: 0.0693 - accuracy: 0.9792 - val_loss: 0.0396 - val_accuracy: 0.9922\n",
      "Epoch 6/15\n",
      "95/95 [==============================] - 127s 1s/step - loss: 0.0664 - accuracy: 0.9786 - val_loss: 0.0369 - val_accuracy: 0.9909\n",
      "Epoch 7/15\n",
      "95/95 [==============================] - 127s 1s/step - loss: 0.0549 - accuracy: 0.9838 - val_loss: 0.0339 - val_accuracy: 0.9935\n",
      "Epoch 8/15\n",
      "95/95 [==============================] - 112s 1s/step - loss: 0.0451 - accuracy: 0.9878 - val_loss: 0.0324 - val_accuracy: 0.9922\n",
      "Epoch 9/15\n",
      "95/95 [==============================] - 113s 1s/step - loss: 0.0461 - accuracy: 0.9855 - val_loss: 0.0309 - val_accuracy: 0.9922\n",
      "Epoch 10/15\n",
      "95/95 [==============================] - 124s 1s/step - loss: 0.0379 - accuracy: 0.9881 - val_loss: 0.0299 - val_accuracy: 0.9935\n",
      "Epoch 11/15\n",
      "95/95 [==============================] - 116s 1s/step - loss: 0.0428 - accuracy: 0.9871 - val_loss: 0.0290 - val_accuracy: 0.9922\n",
      "Epoch 12/15\n",
      "95/95 [==============================] - 115s 1s/step - loss: 0.0311 - accuracy: 0.9908 - val_loss: 0.0286 - val_accuracy: 0.9935\n",
      "Epoch 13/15\n",
      "95/95 [==============================] - 115s 1s/step - loss: 0.0341 - accuracy: 0.9891 - val_loss: 0.0287 - val_accuracy: 0.9935\n",
      "Epoch 14/15\n",
      "95/95 [==============================] - 113s 1s/step - loss: 0.0329 - accuracy: 0.9898 - val_loss: 0.0291 - val_accuracy: 0.9935\n",
      "Epoch 15/15\n",
      "95/95 [==============================] - 116s 1s/step - loss: 0.0341 - accuracy: 0.9901 - val_loss: 0.0306 - val_accuracy: 0.9922\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   with_mask       0.99      0.99      0.99       383\n",
      "without_mask       0.99      0.99      0.99       384\n",
      "\n",
      "    accuracy                           0.99       767\n",
      "   macro avg       0.99      0.99      0.99       767\n",
      "weighted avg       0.99      0.99      0.99       767\n",
      "\n",
      "[INFO] saving mask detector model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# initialize the initial learning rate, number of epochs to train for,\n",
    "# and batch size\n",
    "#initial learning rate \n",
    "INIT_LR = 1e-4\n",
    "#number of epochs\n",
    "EPOCHS = 15\n",
    "#batch size\n",
    "BS = 32\n",
    "\n",
    "dir=r\"E:/face_mask/Face-Mask-Detection-master/dataset\"\n",
    "#in the dataset we have two categories of data so......\n",
    "categories=[\"with_mask\",\"without_mask\"]\n",
    "\n",
    "\n",
    "#lets create two empty lists\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "#iterate through images\n",
    "for category in categories:\n",
    "    path = os.path.join(dir, category)\n",
    "    #iterate through list of images\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        image = load_img(img_path, target_size=(224, 224))\n",
    "        #create an array of images\n",
    "        image = img_to_array(image)\n",
    "        #preprocess the data\n",
    "        image = preprocess_input(image)\n",
    "        data.append(image)\n",
    "        labels.append(category)\n",
    "        #checkpoint\n",
    "#perform encoding on labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "#checkpoint\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "#split the data into train and test\n",
    "(train_x, test_x, train_y, test_y) = train_test_split(data, labels,test_size=0.20, stratify=labels, random_state=42) #80% for training\n",
    "#perform some operations on training images\n",
    "\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,    #<tensorflow.python.keras.preprocessing.image.ImageDataGenerator object at 0x000001F470FB7070>\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "#checkpoint\n",
    "\n",
    "#load the MobileNetV2 network\n",
    "\n",
    "base_model = MobileNetV2(weights=\"imagenet\", include_top=False,input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "head_model = base_model.output\n",
    "head_model = AveragePooling2D(pool_size=(7, 7))(head_model)\n",
    "head_model = Flatten(name=\"flatten\")(head_model)\n",
    "head_model = Dense(128, activation=\"relu\")(head_model)\n",
    "head_model = Dropout(0.5)(head_model)\n",
    "head_model = Dense(2, activation=\"softmax\")(head_model)\n",
    "#checkpoint\n",
    "\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=base_model.input, outputs=head_model)\n",
    "\n",
    "\n",
    "# loop over all layers in the base model and freeze them so they will*not* be updated during the first training process\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "    \n",
    "#compile our model\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "\n",
    "# train the head of the network\n",
    "\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "    aug.flow(train_x, train_y, batch_size=BS),\n",
    "    steps_per_epoch=len(train_x) // BS,\n",
    "    validation_data=(test_x, test_y),\n",
    "    validation_steps=len(test_x) // BS,\n",
    "    epochs=EPOCHS)\n",
    "\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(test_x, batch_size=BS)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(test_y.argmax(axis=1), predIdxs,target_names=lb.classes_))\n",
    "\n",
    "# serialize the model to disk\n",
    "print(\"[INFO] saving mask detector model...\")\n",
    "model.save(\"mask_detect.model\", save_format=\"h5\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc94deb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
